{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/02 21:58:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+---------+---------+---------------+----------+---------------+-------------------------+------------------+--------------------+-------------+----------+------------+------+----------+\n",
      "|cf_contest_id|cf_index|cf_points|cf_rating|        cf_tags|difficulty|generated_tests|is_description_translated|memory_limit_bytes|                name|private_tests|problem_id|public_tests|source|time_limit|\n",
      "+-------------+--------+---------+---------+---------------+----------+---------------+-------------------------+------------------+--------------------+-------------+----------+------------+------+----------+\n",
      "|          322|       A|    500.0|     1000|            [0]|         7|             93|                    false|         256000000|322_A. Ciel and D...|           45|         1|           2|     2|         1|\n",
      "|          760|       D|   1000.0|     1600|         [1, 2]|        10|             51|                    false|         256000000|  760_D. Travel Card|            4|         2|           2|     2|         2|\n",
      "|          569|       E|   1500.0|     2600|         [3, 0]|        11|             99|                    false|         256000000| 569_E. New Language|           17|         3|           3|     2|         2|\n",
      "|          447|       B|   1000.0|     1000|         [0, 4]|         8|            100|                    false|         256000000|447_B. DZY Loves ...|           13|         4|           1|     2|         1|\n",
      "|         1292|       B|    750.0|     1700|[5, 6, 7, 0, 4]|         8|             91|                    false|         256000000|1292_B. Aroma's S...|          131|         5|           3|     2|         1|\n",
      "+-------------+--------+---------+---------+---------------+----------+---------------+-------------------------+------------------+--------------------+-------------+----------+------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Cell 0: Setup\n",
    "##############################################################################\n",
    "\n",
    "# Imports and Spark session setup\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"cs544\")\n",
    "    .master(\"spark://boss:7077\")\n",
    "    .config(\"spark.executor.memory\", \"1G\")\n",
    "    .config(\"spark.sql.warehouse.dir\", \"hdfs://nn:9000/user/hive/warehouse\")\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# Load the problems data and show a sample\n",
    "problems_df = spark.read.json(\"hdfs://nn:9000/problems.jsonl\")\n",
    "problems_df.limit(5).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Cell 1: Q1 - RDD filtering\n",
    "##############################################################################\n",
    "# #q1\n",
    "\n",
    "q1_count = (\n",
    "    problems_df.rdd\n",
    "    .filter(lambda row: row.cf_rating >= 1600 and row.private_tests > 0 and \"_A.\" in row.name)\n",
    "    .count()\n",
    ")\n",
    "\n",
    "# The autograder expects a raw integer on the final line\n",
    "q1_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Cell 2: Q2 - DataFrame filtering\n",
    "##############################################################################\n",
    "# #q2\n",
    "\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "q2_count = (\n",
    "    problems_df\n",
    "    .filter(expr(\"cf_rating >= 1600 AND private_tests > 0 AND name LIKE '%\\\\\\\\_A.%'\"))\n",
    "    .count()\n",
    ")\n",
    "\n",
    "q2_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/02 21:58:37 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/04/02 21:58:37 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "25/04/02 21:58:39 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "25/04/02 21:58:39 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@172.19.0.4\n",
      "25/04/02 21:58:40 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n",
      "25/04/02 21:58:41 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "25/04/02 21:58:41 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "25/04/02 21:58:41 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/04/02 21:58:41 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Cell 3: Q3 - Spark SQL filtering\n",
    "##############################################################################\n",
    "# #q3\n",
    "\n",
    "# Overwrite/create a Hive table for 'problems'\n",
    "problems_df.write.mode(\"overwrite\").saveAsTable(\"problems\")\n",
    "\n",
    "# How many problems are there with cf_rating >= 1600, private_tests > 0, and name containing \"_A.\"?\n",
    "q3_df = spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) as cnt\n",
    "    FROM problems\n",
    "    WHERE cf_rating >= 1600\n",
    "      AND private_tests > 0\n",
    "      AND name LIKE '%\\\\_A.%'\n",
    "\"\"\")\n",
    "q3_val = q3_df.collect()[0][0]\n",
    "\n",
    "q3_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Overwrite/create a Hive table for 'problems'\n",
    "problems_df.write.mode(\"overwrite\").saveAsTable(\"problems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[language#310], functions=[count(1)])\n",
      "   +- HashAggregate(keys=[language#310], functions=[partial_count(1)])\n",
      "      +- FileScan parquet spark_catalog.default.solutions[language#310] Batched: true, Bucketed: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://nn:9000/user/hive/warehouse/solutions], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<language:string>, SelectedBucketsCount: 4 out of 4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Cell 4: Q4 - Bucketing solutions\n",
    "##############################################################################\n",
    "# #q4\n",
    "\n",
    "# 1. Drop any existing 'solutions' table\n",
    "spark.sql(\"DROP TABLE IF EXISTS solutions\")\n",
    "\n",
    "# 2. Load solutions from HDFS into DataFrame\n",
    "solutions_df = spark.read.json(\"hdfs://nn:9000/solutions.jsonl\")\n",
    "\n",
    "# 3. Write the DataFrame as a Hive table with 4 buckets by 'language'\n",
    "(\n",
    "    solutions_df\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .bucketBy(4, \"language\")\n",
    "    .saveAsTable(\"solutions\")\n",
    ")\n",
    "\n",
    "# 4. EXPLAIN the query plan for grouping by language\n",
    "explain_plan = spark.sql(\"\"\"\n",
    "    EXPLAIN\n",
    "    SELECT language, COUNT(*)\n",
    "    FROM solutions\n",
    "    GROUP BY language\n",
    "\"\"\").collect()\n",
    "\n",
    "# We'll just show the plan text lines.\n",
    "for row in explain_plan:\n",
    "    print(row[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'problems': False,\n",
       " 'solutions': False,\n",
       " 'languages': True,\n",
       " 'problem_tests': True,\n",
       " 'sources': True,\n",
       " 'tags': True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Cell 5: Q5 - Warehouse objects\n",
    "##############################################################################\n",
    "# #q5\n",
    "\n",
    "# Read CSV files into DataFrames\n",
    "languages_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"hdfs://nn:9000/languages.csv\")\n",
    "problem_tests_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"hdfs://nn:9000/problem_tests.csv\")\n",
    "sources_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"hdfs://nn:9000/sources.csv\")\n",
    "tags_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"hdfs://nn:9000/tags.csv\")\n",
    "\n",
    "# Create temp views\n",
    "languages_df.createOrReplaceTempView(\"languages\")\n",
    "problem_tests_df.createOrReplaceTempView(\"problem_tests\")\n",
    "sources_df.createOrReplaceTempView(\"sources\")\n",
    "tags_df.createOrReplaceTempView(\"tags\")\n",
    "\n",
    "# A dict of permanent tables vs temp views\n",
    "warehouse_objects = {\n",
    "    'problems': False,   # permanent Hive table\n",
    "    'solutions': False,  # permanent Hive table\n",
    "    'languages': True,   # temp view\n",
    "    'problem_tests': True,\n",
    "    'sources': True,\n",
    "    'tags': True\n",
    "}\n",
    "\n",
    "# Return the dictionary as the final line\n",
    "warehouse_objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10576"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Cell 6: Q6 - correct PYTHON3 solutions from CODEFORCES\n",
    "##############################################################################\n",
    "# #q6\n",
    "\n",
    "q6_df = spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) AS correct_python3_cf\n",
    "    FROM solutions s\n",
    "    JOIN problems p\n",
    "      ON s.problem_id = p.problem_id\n",
    "    JOIN sources so\n",
    "      ON p.source = so.source\n",
    "    WHERE s.is_correct = true\n",
    "      AND s.language = 'PYTHON3'\n",
    "      AND so.source_name = 'CODEFORCES'\n",
    "\"\"\")\n",
    "q6_count = q6_df.collect()[0][0]\n",
    "\n",
    "q6_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Easy': 409, 'Medium': 5768, 'Hard': 2396}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Cell 7: Q7 - categorize problem difficulty\n",
    "##############################################################################\n",
    "# #q7\n",
    "\n",
    "cat_df = spark.sql(\"\"\"\n",
    "    SELECT CASE\n",
    "             WHEN difficulty <= 5 THEN 'Easy'\n",
    "             WHEN difficulty <= 10 THEN 'Medium'\n",
    "             ELSE 'Hard'\n",
    "           END AS difficulty_cat\n",
    "    FROM problems\n",
    "\"\"\")\n",
    "\n",
    "counts_df = cat_df.groupBy(\"difficulty_cat\").count()\n",
    "\n",
    "result_q7 = {}\n",
    "for row in counts_df.collect():\n",
    "    result_q7[row[\"difficulty_cat\"]] = row[\"count\"]\n",
    "\n",
    "# Return dictionary\n",
    "result_q7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7722046375274658, 1.0936036109924316, 0.18015623092651367]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Cell 8: Q8 - caching experiment\n",
    "##############################################################################\n",
    "# #q8\n",
    "\n",
    "import time\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df_nogen = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM problem_tests\n",
    "    WHERE is_generated = false\n",
    "\"\"\")\n",
    "\n",
    "def compute_averages(df):\n",
    "    row = df.select(\n",
    "        avg(\"input_chars\").alias(\"avg_in\"),\n",
    "        avg(\"output_chars\").alias(\"avg_out\")\n",
    "    ).collect()[0]\n",
    "    return (row[\"avg_in\"], row[\"avg_out\"])\n",
    "\n",
    "times = []\n",
    "\n",
    "# a) uncached\n",
    "t0 = time.time()\n",
    "_ = compute_averages(df_nogen)\n",
    "t1 = time.time()\n",
    "times.append(t1 - t0)\n",
    "\n",
    "# b) cache\n",
    "df_nogen.cache()\n",
    "\n",
    "# c) first cached pass\n",
    "t2 = time.time()\n",
    "_ = compute_averages(df_nogen)\n",
    "t3 = time.time()\n",
    "times.append(t3 - t2)\n",
    "\n",
    "# d) second cached pass\n",
    "t4 = time.time()\n",
    "_ = compute_averages(df_nogen)\n",
    "t5 = time.time()\n",
    "times.append(t5 - t4)\n",
    "\n",
    "# e) uncache\n",
    "df_nogen.unpersist()\n",
    "\n",
    "# Return the list of three timings\n",
    "times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5929835263198762"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Cell 9: Q9 - decision tree regression (R^2)\n",
    "##############################################################################\n",
    "# #q9\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "cf_problems_df = spark.sql(\"\"\"\n",
    "SELECT p.*\n",
    "FROM problems p\n",
    "JOIN sources s\n",
    "  ON p.source = s.source\n",
    "WHERE s.source_name = 'CODEFORCES'\n",
    "\"\"\")\n",
    "\n",
    "train_df = cf_problems_df.filter(\"cf_rating > 0 AND (problem_id % 2) = 0\")\n",
    "test_df = cf_problems_df.filter(\"cf_rating > 0 AND (problem_id % 2) = 1\")\n",
    "missing_df = cf_problems_df.filter(\"cf_rating = 0\")\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"difficulty\", \"time_limit\", \"memory_limit_bytes\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "dt = DecisionTreeRegressor(\n",
    "    labelCol=\"cf_rating\",\n",
    "    featuresCol=\"features\",\n",
    "    maxDepth=5\n",
    ")\n",
    "pipeline = Pipeline(stages=[assembler, dt])\n",
    "\n",
    "model = pipeline.fit(train_df)\n",
    "predictions_test = model.transform(test_df)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"cf_rating\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2_score = evaluator.evaluate(predictions_test)\n",
    "\n",
    "r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1887.9377431906614, 1893.1106471816283, 1950.4728638818783)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Cell 10: Q10 - average predictions for missing cf_rating\n",
    "##############################################################################\n",
    "# #q10\n",
    "\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "avg_cf_train = train_df.agg(avg(\"cf_rating\")).collect()[0][0]\n",
    "avg_cf_test = test_df.agg(avg(\"cf_rating\")).collect()[0][0]\n",
    "\n",
    "predictions_missing = model.transform(missing_df)\n",
    "avg_pred_missing = predictions_missing.agg(avg(\"prediction\")).collect()[0][0]\n",
    "\n",
    "# Return the tuple of 3 numbers\n",
    "(avg_cf_train, avg_cf_test, avg_pred_missing)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
